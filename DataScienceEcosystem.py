#!/usr/bin/env python
# coding: utf-8

# Data Science Tools and Ecosystem

# In this notebook, Data Science Tools and Ecosystem are summarized.

# Some of the popular languages that Data Scientists use are:
# 
# 1.  Python: Python is perhaps the most widely used programming language in data science. It has a rich ecosystem of libraries and frameworks like NumPy, pandas, scikit-learn, TensorFlow, and PyTorch that are essential for tasks such as data manipulation, analysis, machine learning, and deep learning.
# 
# 2. R: R is another popular language among statisticians and data scientists. It's particularly strong in statistical analysis and visualization. The R community has developed numerous packages for data manipulation (dplyr), visualization (ggplot2), and machine learning (caret).
# 
# 3. SQL: Structured Query Language (SQL) is essential for working with relational databases. Data scientists use SQL to extract, manipulate, and analyze data stored in databases. It's crucial for data cleaning, transformation, and querying.
# 
# 4.Julia: Julia is a programming language designed for high-performance numerical and scientific computing. It's gaining popularity in the data science community due to its speed and the ability to write code that's both concise and readable.
# 
# 5. Scala: Scala is often used in conjunction with Apache Spark, a powerful big data processing framework. Data scientists use Scala to write Spark applications for large-scale data processing and analysis.
# 
# 6. MATLAB: MATLAB is known for its powerful mathematical and matrix-based capabilities. While it's widely used in academia and engineering, it's also utilized in data analysis and simulation tasks.
# 
# 7. SAS: The SAS programming language is commonly used for advanced analytics, business intelligence, and statistical analysis. It's particularly popular in industries like healthcare and finance.

# Some of the commonly used libraries used by Data Scientists include:
# 
# 1. NumPy: A fundamental library for numerical computations in Python. It provides support for large, multi-dimensional arrays and matrices, as well as various mathematical functions to operate on these arrays.
# 
# 2. pandas: A versatile data manipulation and analysis library. pandas provides data structures like DataFrames and Series, which allow for easy data cleaning, transformation, exploration, and analysis.
# 
# 3. scikit-learn: A machine learning library for Python. scikit-learn provides a wide range of algorithms for tasks such as classification, regression, clustering, dimensionality reduction, and model evaluation.
# 
# 4. TensorFlow: An open-source deep learning framework developed by Google. It's widely used for building and training neural networks for tasks like image recognition, natural language processing, and more.
# 
# 5. PyTorch: Another popular deep learning framework, developed by Facebook's AI Research lab. PyTorch is known for its dynamic computation graph and is preferred by researchers for its flexibility.
# 
# 6. Keras: While it can be used independently, Keras is often used as a high-level neural networks API that runs on top of TensorFlow or other deep learning frameworks. It simplifies the process of building and training neural networks.
# 
# 7. Matplotlib: A widely-used plotting library for creating static, interactive, and animated visualizations in Python.
# 
# 8. Seaborn: Built on top of Matplotlib, Seaborn provides a higher-level interface for creating more aesthetically pleasing and informative statistical visualizations.
# 
# 9. Plotly: A library for interactive and web-based visualizations. It's great for creating interactive graphs and charts for web applications.
# 
# 10 . SciPy: Built on top of NumPy, SciPy adds more functionality for scientific and technical computing, including optimization, integration, interpolation, and more.

# **Objectives**:
# List popular languages for Data Science
# 
# 1. **NumPy**:
#    - **Efficient Array Operations**: NumPy's core functionality is to provide efficient and flexible arrays (ndarrays) for numerical computations, enabling vectorized operations and mathematical functions.
#    - **Mathematical and Logical Operations**: NumPy offers a wide range of mathematical and logical operations on arrays, making it a fundamental tool for scientific computing.
#    - **Linear Algebra**: NumPy includes functions for linear algebra operations such as matrix multiplication, eigenvalues, and singular value decomposition.
#    - **Integration with Other Libraries**: Many other data science libraries build on top of NumPy arrays, making it a foundation for the data science ecosystem.
# 
# 2. **pandas**:
#    - **Data Manipulation**: pandas is designed for data manipulation and analysis, offering data structures like DataFrames and Series for handling structured data efficiently.
#    - **Data Cleaning and Transformation**: pandas provides tools to handle missing data, duplicate values, and apply various data transformations.
#    - **Data Aggregation**: It supports grouping, aggregation, and pivot operations on data to summarize and analyze it effectively.
#    - **Time Series Analysis**: pandas includes functionality for time series data manipulation and analysis, including date and time handling.
# 
# 3. **TensorFlow and PyTorch**:
#    - **Deep Learning**: Both TensorFlow and PyTorch are popular deep learning frameworks used to build, train, and deploy neural networks for various tasks like image recognition, natural language processing, and more.
#    - **Automatic Differentiation**: These frameworks provide automatic differentiation, which is crucial for gradient-based optimization algorithms used in training neural networks.
#    - **GPU Acceleration**: They offer GPU support for faster computations, making it feasible to train complex models on large datasets.
#    - **Flexible Architectures**: PyTorch, in particular, is known for its dynamic computation graph, which allows for more flexible and intuitive model building and debugging.
# 
# 4. **Keras**:
#    - **High-Level API**: Keras is a high-level neural networks API that serves as an interface for building and training neural networks using backends like TensorFlow, Theano, or Microsoft Cognitive Toolkit (CNTK).
#    - **Simplicity and User-Friendly**: Keras abstracts the complexities of the backend frameworks and provides a user-friendly interface for building and experimenting with neural network architectures.
#    - **Rapid Prototyping**: Keras is great for rapid prototyping and experimentation due to its simple syntax and easy model customization.
# 
# Each of these libraries and frameworks plays a crucial role in the data science and machine learning workflow, catering to different aspects of data manipulation, analysis, and model development.

# Data Science Tools
# 
# 1. **Jupyter Notebook / JupyterLab**: Jupyter Notebook is an interactive web application that allows data scientists to create and share documents containing live code, equations, visualizations, and narrative text. JupyterLab is an extended version that offers a more flexible and feature-rich environment.
# 
# 2. **RStudio**: An integrated development environment (IDE) specifically designed for the R programming language. It provides tools for coding, data visualization, and package management.
# 
# 3. **Visual Studio Code**: A versatile code editor that supports multiple programming languages. With extensions, it can be customized to support data science workflows with languages like Python and R.
# 
# 4. **Spyder**: An IDE designed for scientific computing and data analysis using Python. It provides features for data exploration, visualization, and debugging.
# 
# 5. **Tableau**: A powerful data visualization tool that allows users to create interactive and shareable dashboards and reports from various data sources.
# 
# 6. **Power BI**: Microsoft's business analytics service for creating interactive visualizations and business intelligence reports.
# 
# 7. **RapidMiner**: A platform for data science, machine learning, and advanced analytics that provides a graphical interface for building and deploying models.
# 
# 8. **KNIME**: An open-source platform for data analytics, reporting, and integration that allows data scientists to build and deploy workflows using a visual interface.
# 
# 9. **Apache Spark**: An open-source big data processing framework that supports data processing, machine learning, and graph processing. It often works with languages like Scala and Python.
# 
# 10. **Hadoop**: An open-source framework for distributed storage and processing of large datasets. It's often used in conjunction with tools like Spark for big data analysis.
# 
# 11. **Databricks**: A unified analytics platform that integrates with Apache Spark and provides collaborative data science workflows.
# 
# 12. **Git**: A version control system that's essential for collaborative coding and maintaining code history. Platforms like GitHub and GitLab make it easier to host and manage repositories.
# 
# 13. **Docker**: A containerization platform that allows you to package applications and their dependencies into a single unit, making it easier to deploy and manage software across different environments.
# 
# 14. **Anaconda**: A distribution of Python and R specifically aimed at data science tasks. It includes popular libraries, package management tools, and environments.
# 
# 15. **Conda**: A package and environment management system that works alongside Anaconda, helping data scientists manage dependencies and create isolated environments.
# 
# 

# Below are a few examples of evaluating arithmetic expressions in Python
# 
# 
# 1. **Using Basic Arithmetic Operators**:
# ```python
# result = 5 + 3 * 2  # Follows operator precedence (multiplication before addition)
# print(result)  # Output: 11
# 
# result = (5 + 3) * 2  # Parentheses can be used to control precedence
# print(result)  # Output: 16
# ```
# 
# 2. **Using the `eval()` Function (with Caution)**:
# ```python
# expression = "5 + 3 * 2"
# result = eval(expression)
# print(result)  # Output: 11
# ```
# **Note:** Using `eval()` can be risky if the input is not controlled since it can execute arbitrary code.
# 
# 3. **Using the `ast` Module (Safe Evaluation)**:
# ```python
# import ast
# 
# expression = "5 + 3 * 2"
# parsed_expression = ast.parse(expression, mode='eval')
# result = eval(compile(parsed_expression, filename='<string>', mode='eval'))
# print(result)  # Output: 11
# ```
# Using the `ast` module provides safer evaluation compared to `eval()` because it only evaluates expressions and does not execute arbitrary code.
# 
# 4. **Using Third-Party Libraries (e.g., `numpy`)**:
# ```python
# import numpy as np
# 
# result = np.evaluate("5 + 3 * 2")
# print(result)  # Output: 11
# ```
# The `numpy` library can evaluate expressions involving arrays and complex mathematical operations.
# 
# 5. **Using Custom Parsing and Evaluation**:
# ```python
# def evaluate_expression(expression):
#     tokens = expression.split()
#     stack = []
#     operators = {'+': lambda x, y: x + y,
#                  '-': lambda x, y: x - y,
#                  '*': lambda x, y: x * y,
#                  '/': lambda x, y: x / y}
# 
#     for token in tokens:
#         if token.isdigit():
#             stack.append(float(token))
#         elif token in operators:
#             operand2 = stack.pop()
#             operand1 = stack.pop()
#             result = operators[token](operand1, operand2)
#             stack.append(result)
#     
#     return stack[0]
# 
# expression = "5 + 3 * 2"
# result = evaluate_expression(expression)
# print(result)  # Output: 11.0
# ```
# Custom parsing and evaluation allow you to have more control over the process and can be used to handle more complex expressions or introduce additional functionality.

# In[ ]:





# In[3]:


#This a simple arithmetic expression to mutiply then add integers

A = (3*4)+5
print(A)


# In[4]:


#This will convert 200 minutes to hours by diving by 60

# This will convert 200 minutes to hours by dividing by 60.
minutes = 200
hours = minutes / 60
print(hours)


# **Author**
# 
# ##Lakshmi Holla
# 
# ##Niveditha Pandith
# 
# submitted by raiyyan
# 
# 

# In[ ]:




